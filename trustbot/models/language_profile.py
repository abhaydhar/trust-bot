"""
Language profile data models for Agent 0 — Language Intelligence.

A LanguageProfile captures everything downstream agents need to know about a
programming language: regex patterns for chunking, LLM prompts for call
extraction, skip-tokens, block-boundary rules, special-file handling, etc.

Profiles are generated by Agent 0 at index time, persisted as JSON, and
consumed by the chunker, LLM call extractor, structural chunker, and
call-graph builder — eliminating all hardcoded language logic.
"""

from __future__ import annotations

from pydantic import BaseModel, Field


class ForwardDeclarationConfig(BaseModel):
    """Rules for discarding forward declarations (e.g. Delphi interface section)."""

    keyword: str = ""
    strategy: str = "discard_before_keyword_unless_class_prefix"


class SpecialFileConfig(BaseModel):
    """Describes a non-standard file type that needs a dedicated parser.

    Example: Delphi .dfm form files, XAML resource files, etc.
    """

    extension: str
    parser_type: str
    object_pattern: str = ""
    event_pattern: str = ""
    metadata_keys: list[str] = Field(default_factory=list)


class BlockRuleConfig(BaseModel):
    """Open/close block-boundary rule for structural chunking."""

    block_type: str
    open_pattern: str
    close_pattern: str
    name_group: str = "name"


class LanguageProfile(BaseModel):
    """Complete language-specific configuration generated by Agent 0.

    Every downstream module reads this profile instead of relying on
    hardcoded dicts/patterns.
    """

    language: str
    aliases: list[str] = Field(default_factory=list)
    file_extensions: list[str] = Field(default_factory=list)

    # -- Chunking (regex-based) -----------------------------------------------
    function_def_patterns: list[str] = Field(default_factory=list)
    class_def_patterns: list[str] = Field(default_factory=list)
    named_regex_groups: dict[str, str] = Field(default_factory=dict)
    forward_declaration_rules: ForwardDeclarationConfig | None = None
    special_file_types: list[SpecialFileConfig] = Field(default_factory=list)

    # -- Structural chunking (scope-aware) ------------------------------------
    block_rules: list[BlockRuleConfig] = Field(default_factory=list)

    # -- Call extraction -------------------------------------------------------
    llm_call_prompt: str = ""
    skip_tokens: list[str] = Field(default_factory=list)
    supports_bare_identifiers: bool = False
    bare_id_negative_lookahead: str = ""
    call_keyword_patterns: list[str] = Field(default_factory=list)
    call_pattern_examples: list[str] = Field(default_factory=list)
    non_call_examples: list[str] = Field(default_factory=list)

    # -- Comments and strings (for filtering false matches) -------------------
    single_line_comment: str = "//"
    multi_line_comment_open: str = "/*"
    multi_line_comment_close: str = "*/"
    string_delimiters: list[str] = Field(default_factory=lambda: ['"'])

    # -- Metadata --------------------------------------------------------------
    generated_at: str = ""
    source_file_count: int = 0
    validation_coverage: float = 0.0
    codebase_hash: str = ""
